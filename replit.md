### Overview
Accute is an AI-native accounting workflow automation platform aimed at modernizing accounting firms. It automates tasks, boosts efficiency, ensures compliance, and improves accounting practices through intelligent automation. Key features include multi-agent orchestration, a template library, multi-provider AI support, an AI agent marketplace, global payment coverage, native mobile apps, multi-role authentication, custom workflow building, and secure document management. The platform seeks to transform the accounting industry with an AI-native solution for accounting automation, presenting significant market potential.

### User Preferences
- Prefer database-backed storage over in-memory
- Enterprise-grade security is paramount
- Multi-provider AI support essential
- Clean, modern UI following design guidelines
- Comprehensive audit trail for compliance
- ENCRYPTION_KEY environment variable must be stable across deployments to prevent LLM credential decryption failures
- Luca Agent Personality: Luca now asks follow-up questions BEFORE answering to narrow down exact requirements
- Luca Agent Approach: Luca asks 2-3 targeted clarifying questions to understand context
- Strict Agent Role Boundaries: All 10 AI agents enforce strict domain boundaries with polite refusals for out-of-scope questions. Each agent's system prompt includes STRICT ROLE BOUNDARIES section listing allowed/prohibited topics and standardized refusal templates that redirect users to appropriate specialists. Luca explicitly includes IRS, tax authorities, and tax law as core allowed topics (NOT prohibited).
- Email Sanitization: All email fields (fromEmail, subject, organizationName, roleName, inviteUrl) sanitized using `sanitizeForEmail()` to replace Unicode smart quotes and special characters with ASCII equivalents, preventing Resend ByteString conversion errors.
- Error Handling: Team creation and other endpoints use `instanceof ZodError` for reliable validation error detection, returning 400 status with detailed validation messages.
- Duplicate Relationship Prevention: Supervision endpoint includes pre-flight duplicate check, returning 409 Conflict for existing relationships instead of 500 database constraint errors.
- Workspace Creation: Full workspace creation flow with dialog UI, auto-slug generation, and organization setup. ALWAYS updates creator's organizationId and defaultOrganizationId to new workspace (not just for first workspace), unsets isDefault flag on other memberships, and requires re-authentication at /auth/login to access new workspace.
- Server Initialization Performance: RBAC seeding uses bulk upsert operations (chunks of 50) with `onConflictDoUpdate` for permissions and in-memory diffing for role-permission assignments, reducing 600+ serial DB operations to ~10 bulk operations for sub-second initialization.
- Automatic LLM Configuration: OrganizationOnboardingService creates default LLM configurations only when valid API keys are present in environment. Priority: OpenAI > Anthropic > Azure (requires full config: API key, endpoint, deployment name). When no credentials available, config creation is skipped (returns null) instead of creating hardcoded placeholders. Admins must configure LLM credentials manually via Settings UI. Existing organizations can be backfilled via `tsx server/backfill-llm-configs.ts`.
- Secure Registration Flow (Option B): Users register with ONLY email/username (no password during registration). After submitting registration, users receive verification email. Clicking verification link redirects to set-password page where they create their password. This ensures email ownership is verified before password creation, preventing account creation with fake emails. Flow: Register → Verify Email → Set Password → Login. Legacy users (registered before email verification) auto-verified on first login to prevent lockouts.
- Email Verification System: Comprehensive email verification for new user registrations. All registration endpoints (/api/auth/register, /api/auth/register-admin, /api/super-admin/register) do NOT require password field. Shared sendVerificationEmail() helper centralizes token generation and Mailgun email delivery. Verification endpoint returns token for password setup. /api/auth/set-password endpoint allows users to set password after verification. Login endpoint blocks unverified NEW users only (legacy users with passwords auto-allowed). Invitation-based registrations auto-verify (proves mailbox access).
- Error Handling Enhancement: API error responses properly parsed as JSON with clean error messages. The throwIfResNotOk() function extracts error details from JSON responses and attaches them to Error objects for proper frontend display.
- Resource Management RBAC: 14 new permissions added (resource_allocations.*, skills.*, user_skills.*, task_matching.suggest) with role-based access. Admin: full CRUD; Employee: self-service skills + taxonomy read; Client: none. Gated via resource_management feature identifier. Database migration completed via manual SQL (featureIdentifiers jsonb column added to subscription_plans).
- AI Personality Profiling & Performance Monitoring: Revolutionary multi-framework personality assessment system combining Big Five (OCEAN), DISC, MBTI, Emotional Intelligence, and Hofstede Cultural Dimensions. Includes database-backed ML job queue, hybrid ML analysis, admin dashboard for batch analysis and monitoring, employee/client UI for self-service profiles, and statistical correlation analysis with performance metrics.
- Security & Startup Architecture: Vite middleware initializes immediately after server.listen() to prevent routing gaps. Environment variable validation in `server/index.ts` with fail-fast for missing secrets (`ENCRYPTION_KEY` validation supports base64, hex, or legacy strings). No `dotenv` dependency. `JWT_SECRET` and `ENCRYPTION_KEY` have no `crypto.randomBytes()` fallbacks. Startup log order guarantees routing health before heavy initialization.
- IDOR Protection: Fixed critical Insecure Direct Object Reference vulnerabilities in workflow endpoints by verifying `organizationId` and ownership before returning, updating, or deleting resources. All fixes return 404 to prevent information disclosure. Super admins can access all resources.
- Personalized Welcome Messages: Login system tracks `lastLoginAt` to distinguish first-time vs. returning users. First-time users see "Welcome!" while returning users see "Welcome back!" for a more personalized greeting. Both regular and MFA login flows support this feature.
- Country Code Phone Field: Users table includes mandatory `countryCode` field (default "+1") with dropdown UI containing 30 common country codes. Employee profile form validates and combines countryCode + phone before OTP verification. Backend API whitelists countryCode for profile updates.
- LLM Auto-Selection Fix: Luca chat widget properly auto-selects LLM configuration on load. Fixed bug where empty string initial state prevented auto-selection useEffect from running. Now correctly prioritizes workspace default configs over user configs, with fallback to first available config.
- Luca Chat Widget UI Enhancements: Added tooltip to floating button showing "Ask Luca - AI Accounting Expert" on hover. Palm leaf preview state now includes a close button positioned above the stack. Fixed overlapping X icons in full chat dialog by hiding Dialog's default close button with `[&>button]:hidden` CSS selector. All buttons comply with Shadcn guidelines (no custom height/width overrides or hover colors).
- Contact Creation Bug Fix: Fixed 500 error when creating contacts during client onboarding. Issue was insertContactSchema requiring organizationId and createdBy fields that are added by backend from auth context. Schema now omits these fields (marked with "Added by backend from auth context" comments), allowing validation to pass before backend enrichment.
- Workspace Settings Save Fix: Fixed critical bug where workspace settings API calls used wrong endpoint (`/api/organizations/${orgId}/settings` vs correct `/api/organizations/${orgId}`), causing settings to not save and users to get logged out. Updated all query keys and mutations in organization-settings.tsx to use correct endpoint.
- LLM Configuration Form UX: Enhanced workspace LLM configuration form with comprehensive validation feedback. All required fields marked with * suffix, optional fields clearly labeled. Added FormDescription help text for every field explaining purpose, format requirements, and examples. Azure-specific fields conditionally shown with clear "(Required for Azure)" labels.
- Centralized LLM Middleware: All 10 static agents (Luca, Parity, Cadence, Forma, Echo, Relay, Scribe, Radar, OmniSpectra, Lynk) migrated to use withLLMConfig middleware for centralized LLM configuration management. Middleware provides automatic workspace→user fallback, 5-minute caching (reduces DB load ~95%), consistent error handling, and scales to infinite agents. HTTP endpoints use withLLMConfig wrapper, file uploads use getLLMConfig helper with .catch(() => null) for optional configs, WebSocket handlers use getLLMConfig directly. Cache automatically invalidated on all LLM config CRUD operations. Template available at docs/agent-template.md.
- Critical Agent Routing Fix: Restructured server initialization to prevent Vite's catch-all middleware from intercepting /api/agents/* endpoints. ROOT CAUSE: Agent routes were registered during background initialization AFTER Vite's catch-all was active, causing HTML responses instead of JSON. SOLUTION: Sequential initialization order in server/index.ts: (1) server.listen() for fast health checks, (2) await initializeSystem(app) blocks until agents ready, (3) register all agent routes AFTER agents initialized, (4) setupVite() adds catch-all middleware LAST. Each step wrapped in try/catch with graceful degradation via setInitializationStatus(). This eliminates race conditions and ensures /api/agents/* routes exist before Vite intercepts requests.
- Universal LLM Selectors: All 10 AI agents now feature frontend LLM configuration selectors with consistent UX. Agents with session sidebars (Cadence, Parity, Forma, Echo, Relay, Scribe, Luca, Lynk) display selector in CardFooter at sidebar bottom; agents without sidebars (Radar, OmniSpectra) show selector in CardHeader. Auto-selection prioritizes default configs with fallback to first available config. API integration uses conditional spreading `...(selectedLlmConfig && { llmConfigId: selectedLlmConfig })` to prevent empty string payloads that trigger 400 errors. File uploads conditionally append llmConfigId only when truthy. All agents gracefully handle loading states and missing configs.

### System Architecture

#### UI/UX Decisions
The UI/UX is inspired by Linear and Notion, using the Carbon Design System. It features a Porsche-to-Pink gradient, specific fonts (Orbitron, Inter, Fira Code), a collapsible sidebar, top navigation, card-based dashboards, and data tables. It is implemented as a responsive Progressive Web App (PWA).

#### Technical Implementations
The frontend uses React 18, TypeScript, Vite, Tailwind CSS, and shadcn/ui. The backend is built with Node.js, Express, and TypeScript, using PostgreSQL (Neon) via Drizzle ORM. Authentication relies on JWT and bcrypt, with AES-256 encryption, RBAC, rate limiting, and SQL injection prevention. AI integration supports OpenAI, Azure OpenAI, and Anthropic Claude. The platform is optimized for Replit's Cloud Run/Autoscale.

#### Feature Specifications
Accute features a multi-tenant architecture with a four-tier Role-Based Access Control (Super Admin, Admin, Employee, Client) and a Client Portal. Core features include an AI Client Onboarding System, conversational AI agent interfaces, a unified workflows system with visual automation, an AI Agent Marketplace, Secure LLM Configuration Management with AES-256-GCM encryption, PKI Digital Signatures for document verification, and Secure Document Management with encrypted storage. Additional features include a Marketplace System for templates, Projects Management, an AI Agent Foundry, Subscription Management, Document Version Control, Enhanced Report Builder, Workload View, Unified Inbox, Calendar & Event Management, Recurring Scheduler, Collaboration features, Enhanced Automation Actions, Workload Insights, Luca Chat features (File Attachments, Auto Chat Title, Search & Archive), Idempotent Automatic Day 1 Task Creation, 21-Day Onboarding Journey, Profile Picture Upload, Two-Level LLM Configuration System, Client Payment Collection System, Email Integration, SSO/SAML Enterprise Authentication, Proposals & Quotes Management, Chat Threading Extension, and a Resource Management Suite with a Skills Management System and Skill Matching Engine. A WebRTC Voice/Video Calling System provides production-ready in-app calling.

#### System Design Choices
The project is structured into `client/`, `server/`, and `shared/` directories. Security is a core focus, with robust authentication, encryption, and multi-tenancy. The Automation Engine supports various action types with context propagation. AI agents are accessed via dynamic routing with lazy-loaded components. A centralized `LLMConfigService` manages all LLM configurations with 5-minute caching and workspace→user fallback logic, accessed via `withLLMConfig` middleware for HTTP endpoints and `getLLMConfig` helper for WebSocket handlers. File attachments for AI agents are handled by a `FileParserService` supporting PDF, DOCX, XLSX/XLS, CSV, and TXT formats. WebSocket management is lazy-loaded on-demand for chat sessions.

### External Dependencies
- PostgreSQL (via Neon)
- OpenAI API
- Azure OpenAI API
- Anthropic Claude API
- Mailgun
- MSG91
- Razorpay
- Stripe
- PayU
- Payoneer
- Gmail API
- Multer
- expr-eval
- Recharts
- pdf-parse
- mammoth
- xlsx